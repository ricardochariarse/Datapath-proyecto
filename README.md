# Lakehouse QAPITAL


## üéØ Descripci√≥n del proyecto

Este proyecto fue desarrollado como parte del programa **Microsoft Fabric Data Engineer** de **Datapath**, con el objetivo de construir una plataforma **data-driven** para la empresa **QAPITAL S.A.**, dedicada al desarrollo y comercializaci√≥n de proyectos inmobiliarios en LATAM.

El caso de uso consisti√≥ en **integrar fuentes dispersas de informaci√≥n** (ventas, marketing, leads, brokers, propiedades y proyectos) dentro de una arquitectura **Lakehouse en Microsoft Fabric**, habilitando anal√≠tica descriptiva de desempe√±o comercial y marketing.

---

## ‚öôÔ∏è Arquitectura general

La soluci√≥n se dise√±√≥ bajo el enfoque **medallion (Bronze‚ÄìSilver‚ÄìGold)** utilizando componentes nativos de **Microsoft Fabric**:

| Etapa | Descripci√≥n | Herramienta |
|-------|--------------|--------------|
| **Fuente** | Datos alojados en ADLS Gen2 | Azure Data Lake Storage |
| **Ingesta** | Pipelines para orquestar extracci√≥n y carga | Fabric Data Factory |
| **Transformaci√≥n** | Limpieza, uni√≥n y modelado en Notebooks PySpark | Fabric Notebooks |
| **Procesamiento** | Lakehouse + OneLake con tablas Delta | OneLake |
| **Modelo sem√°ntico** | Warehouse + Semantic Model para consumo | Fabric Warehouse |
| **Consumo** | Dashboards interactivos para Pricing, Marketing ROI e Inventario | Power BI |

### üìä Diagrama de arquitectura
![Arquitectura Lakehouse QAPITAL](Imagenes/QATAR_ARQUITECTURA.png)

---

## üß© Modelo de datos

El modelo final est√° compuesto por **hechos y dimensiones**, optimizado para anal√≠tica de performance comercial:

- **Hechos:** `fact_sales`, `fact_leads`  
- **Dimensiones:** `dim_clients`, `dim_brokers`, `dim_properties`, `dim_projects`, `dim_campaigns`

### üìò Relaciones entre tablas
![Modelo relacional](Imagenes/Esquema.png)

---

## üîÑ Pipeline de orquestaci√≥n

El **pipeline principal** gestiona la ejecuci√≥n autom√°tica del flujo completo:
![Modelo relacional](Imagenes/Pipeline.png)

1. Extracci√≥n desde ADLS Gen2  
2. Transformaci√≥n en tres notebooks (Bronze ‚Üí Silver ‚Üí Gold)  
3. Actualizaci√≥n del modelo sem√°ntico  
4. Env√≠o de alertas por correo si el proceso finaliza correctamente o con errores  

El archivo JSON del pipeline y los notebooks se encuentran en este repositorio para su revisi√≥n y reutilizaci√≥n.

---

## üß∞ Tecnolog√≠as utilizadas

- **Microsoft Fabric**
- **OneLake / Lakehouse**
- **Data Factory Pipelines**
- **PySpark (Notebooks)**
- **Power BI**
- **Delta Tables**
- **Azure Data Lake Gen2**

---

## üìà Resultados esperados

- Reducci√≥n del *time-to-insight* de **48 h a 3 h**  
- Vista unificada del inventario inmobiliario y campa√±as  
- Capacidad de revisar los reportes de forma diaria  
- Gobernanza completa sobre datos personales y trazabilidad de procesos  

---
